{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea7195c",
   "metadata": {},
   "source": [
    "# Boston Housing Project\n",
    "Generated automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd83692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30828910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot MEDV\n",
    "plt.boxplot(df['MEDV'])\n",
    "plt.title('Boxplot of MEDV')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599d6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1 — Summary Statistics & Missing Values\n",
    "\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df[\"MEDV\"] = boston.target\n",
    "\n",
    "# 1. Dataset Information\n",
    "print(\"### Dataset Info ###\")\n",
    "print(df.info())\n",
    "\n",
    "# 2. Summary Statistics\n",
    "print(\"\\n### Summary Statistics ###\")\n",
    "print(df.describe())\n",
    "\n",
    "# 3. Check Missing Values\n",
    "print(\"\\n### Missing Values ###\")\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fdb3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2 — Visualizations with Matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# Load Data\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df[\"MEDV\"] = boston.target\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Histogram for MEDV\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(df['MEDV'], bins=20)\n",
    "plt.title('Histogram of MEDV')\n",
    "plt.xlabel('Median Value (MEDV)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Scatter Plot — RM vs MEDV\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.scatter(df['RM'], df['MEDV'])\n",
    "plt.title('Scatter Plot: RM vs MEDV')\n",
    "plt.xlabel('Average Rooms per Dwelling (RM)')\n",
    "plt.ylabel('MEDV')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Boxplot of MEDV\n",
    "# -------------------------------\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.boxplot(df['MEDV'])\n",
    "plt.title('Boxplot of MEDV')\n",
    "plt.ylabel('MEDV')\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Bar Plot — CHAS (0 = no river, 1 = river)\n",
    "# -------------------------------\n",
    "chas_counts = df['CHAS'].value_counts().sort_index()\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(chas_counts.index.astype(str), chas_counts.values)\n",
    "plt.title('Bar Plot of CHAS')\n",
    "plt.xlabel('CHAS (0 = No River, 1 = River)')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "for i, v in enumerate(chas_counts.values):\n",
    "    plt.text(i, v + 1, str(v), ha='center')\n",
    "\n",
    "plt.grid(True, linestyle='--', alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# -------------------------------\n",
    "# 5. Correlation Heatmap (Matplotlib only)\n",
    "# -------------------------------\n",
    "corr = df.corr()\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.imshow(corr, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.columns)), corr.columns)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d852810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3 — Hypothesis Testing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load dataset\n",
    "boston = load_boston()\n",
    "df = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "df['MEDV'] = boston.target\n",
    "\n",
    "alpha = 0.05   # significance level\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. T-Test: Is MEDV significantly different for CHAS = 0 vs 1\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "medv_chas0 = df[df['CHAS'] == 0]['MEDV']\n",
    "medv_chas1 = df[df['CHAS'] == 1]['MEDV']\n",
    "\n",
    "t_stat, p_val = stats.ttest_ind(medv_chas0, medv_chas1, equal_var=False)\n",
    "\n",
    "print(\"### T-Test (MEDV ~ CHAS) ###\")\n",
    "print(\"T-statistic:\", t_stat)\n",
    "print(\"P-value:\", p_val)\n",
    "\n",
    "if p_val < alpha:\n",
    "    print(\"Conclusion: Reject H0 — Significant difference in MEDV between CHAS groups.\\n\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject H0 — No significant difference.\\n\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. ANOVA: MEDV across AGE groups\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Create AGE groups\n",
    "bins = [-1, 35, 70, 200]\n",
    "labels = ['<=35', '36-70', '>70']\n",
    "df['AGE_Group'] = pd.cut(df['AGE'], bins=bins, labels=labels)\n",
    "\n",
    "group1 = df[df['AGE_Group'] == '<=35']['MEDV']\n",
    "group2 = df[df['AGE_Group'] == '36-70']['MEDV']\n",
    "group3 = df[df['AGE_Group'] == '>70']['MEDV']\n",
    "\n",
    "f_stat, p_val_anova = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "print(\"### ANOVA (MEDV ~ AGE Groups) ###\")\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"P-value:\", p_val_anova)\n",
    "\n",
    "if p_val_anova < alpha:\n",
    "    print(\"Conclusion: Reject H0 — At least one AGE group mean is different.\\n\")\n",
    "else:\n",
    "    print(\"Conclusion: Fail to reject H0 — No significant difference.\\n\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Pearson Correlation — NOX vs INDUS\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "r, p_corr = stats.pearsonr(df['NOX'], df['INDUS'])\n",
    "\n",
    "print(\"### Pearson Correlation (NOX vs INDUS) ###\")\n",
    "print(\"Correlation coefficient (r):\", r)\n",
    "print(\"P-value:\", p_corr)\n",
    "\n",
    "if p_corr < alpha:\n",
    "    print(\"Conclusion: Significant linear relationship between NOX and INDUS.\\n\")\n",
    "else:\n",
    "    print(\"Conclusion: No significant linear correlation.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c60a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# TASK 4: FEATURE SCALING\n",
    "# MinMaxScaler, StandardScaler, RobustScaler\n",
    "# ------------------------------\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Select only numerical columns for scaling\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "num_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626eb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax Scaling\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(minmax_scaler.fit_transform(df[num_cols]), \n",
    "                         columns=[col + '_minmax' for col in num_cols])\n",
    "\n",
    "print(\"MinMax Scaled Data:\")\n",
    "df_minmax.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250843d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "standard_scaler = StandardScaler()\n",
    "df_standard = pd.DataFrame(standard_scaler.fit_transform(df[num_cols]),\n",
    "                           columns=[col + '_standard' for col in num_cols])\n",
    "\n",
    "print(\"Standard Scaled Data:\")\n",
    "df_standard.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521fd859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust Scaling (good when dataset has outliers)\n",
    "robust_scaler = RobustScaler()\n",
    "df_robust = pd.DataFrame(robust_scaler.fit_transform(df[num_cols]),\n",
    "                         columns=[col + '_robust' for col in num_cols])\n",
    "\n",
    "print(\"Robust Scaled Data:\")\n",
    "df_robust.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813bc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_combined = pd.concat([df_minmax, df_standard, df_robust], axis=1)\n",
    "df_scaled_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27923b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled_combined.to_csv(\"scaled_output.csv\", index=False)\n",
    "print(\"Scaling completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3850c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# TASK 5: CATEGORICAL ENCODING\n",
    "# OHE, LabelEncoder, OrdinalEncoder\n",
    "# ---------------------------------------\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns\n",
    "cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0e1708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for categorical columns\n",
    "ohe = OneHotEncoder(sparse_output=False, drop='first')   # drop first to avoid dummy trap\n",
    "\n",
    "df_ohe = pd.DataFrame(\n",
    "    ohe.fit_transform(df[cat_cols]),\n",
    "    columns=ohe.get_feature_names_out(cat_cols)\n",
    ")\n",
    "\n",
    "df_ohe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305fb6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label Encoding\n",
    "df_label = df.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_label[col + \"_label\"] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le  # store encoder\n",
    "\n",
    "df_label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5795cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of ordinal mapping\n",
    "ordinal_cols = ['Education', 'Size', 'Priority']  # change based on your dataset\n",
    "\n",
    "# Filter only the columns that actually exist in df\n",
    "ordinal_cols = [col for col in ordinal_cols if col in df.columns]\n",
    "\n",
    "ordinal_categories = [\n",
    "    ['Low', 'Medium', 'High'],   # for Education\n",
    "    ['Small', 'Medium', 'Large'], # for Size\n",
    "    ['Low', 'Medium', 'High']    # for Priority\n",
    "]\n",
    "\n",
    "ord_enc = OrdinalEncoder(categories=ordinal_categories)\n",
    "\n",
    "df_ordinal = df.copy()\n",
    "df_ordinal[ordinal_cols] = ord_enc.fit_transform(df[ordinal_cols])\n",
    "\n",
    "df_ordinal.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608f1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_combined = pd.concat(\n",
    "    [df.drop(columns=cat_cols), df_ohe, df_label[[col + \"_label\" for col in cat_cols]]],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_encoded_combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752fcba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_combined.to_csv(\"encoded_output.csv\", index=False)\n",
    "print(\"Categorical Encoding Completed Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f22f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
